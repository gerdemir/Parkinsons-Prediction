{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af382a7-dfb5-4f90-88ad-0cba8f1b9333",
   "metadata": {},
   "source": [
    "# **Parkinsons Disease Prediction using Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc5832-d45c-49da-9ef7-8d7295769160",
   "metadata": {},
   "source": [
    "The dataset used in this project is the Parkinson's Disease dataset:\n",
    "www.kaggle.com/datasets/thecansin/parkinsons-data-set\n",
    "\n",
    "Dataset Citation:\n",
    "'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection',\n",
    "Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM.\n",
    "BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)\n",
    "\n",
    "## Dataset Features\n",
    "\n",
    "1. **name** – Subject name and recording number (ASCII string identifier).\n",
    "2. **MDVP\\:Fo(Hz)** – Average vocal fundamental frequency (pitch).\n",
    "3. **MDVP\\:Fhi(Hz)** – Maximum vocal fundamental frequency.\n",
    "4. **MDVP\\:Flo(Hz)** – Minimum vocal fundamental frequency.\n",
    "5. **MDVP\\:Jitter(%)** – Percentage of cycle-to-cycle variation in pitch.\n",
    "6. **MDVP\\:Jitter(Abs)** – Absolute Jitter.\n",
    "7. **MDVP\\:RAP** – Relative average perturbation.\n",
    "8. **MDVP\\:PPQ** – Five-point period perturbation quotient.\n",
    "9. **Jitter\\:DDP** – Difference of differences of periods (3 × RAP).\n",
    "10. **MDVP\\:Shimmer** – Local shimmer in amplitude.\n",
    "11. **MDVP\\:Shimmer(dB)** – Shimmer in decibels.\n",
    "12. **Shimmer\\:APQ3** – Three-point amplitude perturbation quotient.\n",
    "13. **Shimmer\\:APQ5** – Five-point amplitude perturbation quotient.\n",
    "14. **MDVP\\:APQ** – Eleven-point amplitude perturbation quotient.\n",
    "15. **Shimmer\\:DDA** – Average absolute difference of differences of consecutive amplitudes.\n",
    "16. **NHR** – Noise-to-Harmonics Ratio.\n",
    "17. **HNR** – Harmonics-to-Noise Ratio.\n",
    "18. **RPDE** – Recurrence Period Density Entropy (nonlinear measure of signal periodicity).\n",
    "19. **D2** – Correlation dimension (signal complexity).\n",
    "20. **DFA** – Detrended Fluctuation Analysis (signal fractal scaling exponent).\n",
    "21. **spread1** – First measure of nonlinear spread of fundamental frequency.\n",
    "22. **spread2** – Second measure of nonlinear spread of fundamental frequency.\n",
    "23. **PPE** – Pitch Period Entropy (irregularity in pitch).\n",
    "24. **status** – Health status of subject:\n",
    " * `1` = Parkinson’s disease**\n",
    "*  `0` = Healthy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7e056-1c89-4d05-af44-47332cb105d7",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b2241-2ddc-411f-a785-a22754b57d2d",
   "metadata": {},
   "source": [
    "## 1.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6095e71f-f37a-4837-a4c5-f4fbe4bd5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     # linear algebra\n",
    "import pandas as pd    # data manipulation\n",
    "import seaborn as sns   # data visualization\n",
    "import pickle  # library for saving and loading the model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8b021-6230-49c6-b980-8aaedf9a2bc9",
   "metadata": {},
   "source": [
    "## 1.2. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69009fcd-12cf-4a86-943a-ca1189cb46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a pandas dataframe\n",
    "df = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab765660-4544-4cf7-bd99-9d843b1b3d36",
   "metadata": {},
   "source": [
    "## 1.3. Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9efd2-6852-4305-972a-08e5cf2cbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58077868-236f-4a20-9299-f9591ca755d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb550eea-df30-41a4-8383-40c220a86a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1629650-e59f-40af-b5c0-c50841363b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894945e-ed14-4ce3-b616-b4d7a42bad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.replace(\":\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"%\", \"perc\"))\n",
    "\n",
    "print(\"Yeni kolonlar:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f241ce6-b9b1-4cd1-8cf3-16e9d19d7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ac33f-a0ba-4609-a096-0f3fc21aeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992d843-78f7-48b1-989c-7d2b1e8f6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistical measures of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5017b1b-2006-4c8d-b76b-3f54f9300eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display what unique value in dependent columns\n",
    "df['status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7d123-14eb-44a3-b6e5-fc0c9eb16cbc",
   "metadata": {},
   "source": [
    "#### 0 --> Healthy\n",
    "\n",
    "#### 1 --> Parkinson's Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09f9e2-c1fc-4a63-ab1b-422aaf4fb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display how many different values are in each unique value\n",
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5107b59-5e40-4992-ada2-72bf66aa9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see mean unique values for each columns\n",
    "df.groupby('status').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662712f-81bf-4aa5-aaa1-11d3e7c08823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().status.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050edb7e-82d4-4f21-afdb-2a5aeb52eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating dependent and independent data\n",
    "X = df.drop(columns = 'status', axis=1)\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c86d2-13b0-43e3-b578-7ab8a0695cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd04562-0848-4daf-a197-57c25648e6e0",
   "metadata": {},
   "source": [
    "# 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ff06e-b799-42b2-86f0-5223ad176b6c",
   "metadata": {},
   "source": [
    "## 2.1. Splitting to Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4dcbe-6cbd-4a6d-8641-4c757206d83e",
   "metadata": {},
   "source": [
    "test_size=0.2, 20% of dataset goes to test set, 80% to training\n",
    "\n",
    "random_state=2      # ensures reproducibility, controls randomness\n",
    "\n",
    "If you set it (e.g., 2), you’ll always get the same split each time you run the code. This is good for reproducibility.\n",
    "\n",
    "If you leave it as default (None), the split will change every time you run the code (since it uses system time as the seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83af25-81d2-4bd2-9648-8463854cc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988b4e7-dd59-413f-a016-bd0cf8a7aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6589c8-818d-49f3-930b-fb8ae4342bf8",
   "metadata": {},
   "source": [
    "## 2.2. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba2d6c-4af8-4d5d-9d10-65939e44bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "standardized_data = scaler.transform(X_train)  #scaler.fit_transform()\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b50e7-6d89-4a48-9d02-d2a154ca1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(\"scaler_parkinson.sav\", \"wb\"))\n",
    "\n",
    "pickle.load(open('scaler_parkinson.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6048165-9650-4542-aced-ff9bc2dc6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab438e8-4464-4e4a-a415-b5ff98c9516e",
   "metadata": {},
   "source": [
    "## 2.3. Model Training\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3591f4ef-e7ec-486b-90c9-a70186e12172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# set up the model\n",
    "model_svc = svm.SVC(kernel= 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b330a-d70d-4717-9e70-cece392be704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Support Vector Machine Classifier\n",
    "model_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c79aae-c5d9-4e87-ae98-316d94159b59",
   "metadata": {},
   "source": [
    "## 2.4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa2671-6d5a-490e-b8b6-2549f7467339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to evaluate model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy on training data\n",
    "X_train_prediction_svc = model_svc.predict(X_train)\n",
    "training_data_accuracy_svc = accuracy_score(X_train_prediction_svc, y_train)\n",
    "\n",
    "print('Accuracy on training data for SVC: ', training_data_accuracy_svc)\n",
    "\n",
    "# accuracy on test data\n",
    "X_test_prediction_svc = model_svc.predict(X_test)\n",
    "test_data_accuracy_svc = accuracy_score(X_test_prediction_svc, y_test)\n",
    "\n",
    "print('Accuracy on test data for SVC: ' , test_data_accuracy_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf6511-84b9-4f0a-a3df-22d2eda5ab8d",
   "metadata": {},
   "source": [
    "# 3. Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15ad7a-bf3d-47c5-897c-db92f42b1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = (113.71500,116.44300,96.91300,0.00349,0.00003,0.00171,0.00203,0.00514,0.01472,0.13300,0.00748,0.00905,0.01148,0.02245,0.00478,26.54700,0.380253,0.766700,-5.943501,0.192150,1.852542,0.179677)\n",
    "\n",
    "# change the input data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the np array as we are predicting for one instance \n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "# standardize the input data\n",
    "std_data = scaler.transform(input_data_reshaped)\n",
    "\n",
    "# get prediction\n",
    "prediction = model_svc.predict(std_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b14ac-0126-4a5d-840e-a926c3af3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction[0]== 0:\n",
    "    print(\"The person does not have Parkinsons Disease.\")\n",
    "else:\n",
    "    print(\"The person has Parkinsons Disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc0c57-46e8-44af-923a-8aad7eaee52c",
   "metadata": {},
   "source": [
    "# 4. Model Deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07bcd5-ac0c-45b9-a048-3abc8e5bbdff",
   "metadata": {},
   "source": [
    "## 4.1. Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8240d-355c-49d6-a27e-9d13f48eb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "filename = 'trained_model_parkinson.sav'\n",
    "pickle.dump(model_svc, open(filename, 'wb'))\n",
    "\n",
    "# load the saved model\n",
    "loaded_model = pickle.load(open('trained_model_parkinson.sav', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
